{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/nyu-mll/jiant/blob/e6d90621ef7e6277d4fd92241fea8b5646352e64/guides/tasks/adding_tasks.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    1. A (new) task file: jiant/tasks/lib/senteval/mytask.py\n",
    "    2. The task retrieval library: jiant/tasks/retrieval.py\n",
    "    3. The evaluation library: jiant/tasks/evaluate/core.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " exemple : implémentation de udep, panx, ccg\n",
    " attention panx, udep sont des benchmarks avec des sous-tâches ... ça doit rien changer en théorie sur cette partie\n",
    " jiant/jiant/tasks/lib/\n",
    " \n",
    " essentiellement: changer la liste de labels, et écrire une fonction pour lire les données, cf panx qui est du NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dans retrieval\n",
    "\n",
    "TASK_DICT = {\n",
    "# ...\n",
    "\t\"mytask\": MyTask,\n",
    "# ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dans evaluate, ajouter ici la tâche\n",
    "\n",
    "elif isinstance(task, (tasks.UdposTask, tasks.PanxTask, tasks.MyTask)):\n",
    "        return F1TaggingEvaluationScheme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il faut aussi régler la question du téléchargement, expliqué dans le doc adding_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour tokenclassif: ajoute juste une couche de projection sur les labels (avec un dropout). \n",
    "si on veut qqchose de plus évolué il faut changer ça dans \n",
    "jiant/jiant/proj/main/modeling/heads.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@JiantHeadFactory.register([TaskTypes.TAGGING])\n",
    "class TokenClassificationHead(BaseHead):\n",
    "    def __init__(self, task, hidden_size, hidden_dropout_prob, **kwargs):\n",
    "        \"\"\"From RobertaForTokenClassification\"\"\"\n",
    "        super().__init__()\n",
    "        self.num_labels = len(task.LABELS)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, unpooled):\n",
    "        unpooled = self.dropout(unpooled)\n",
    "        logits = self.classifier(unpooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototype modification\n",
    "recurrent_modules = {\n",
    "    \"lstm\": nn.LSTM,\n",
    "    \"gru\": nn.GRU,\n",
    "}\n",
    "\n",
    "lstm_cfg = {\n",
    "    \"hidden_size\": 100,\n",
    "    \"bidirectional\": False,\n",
    "    \n",
    "}\n",
    "\n",
    "@JiantHeadFactory.register([TaskTypes.TAGGING])\n",
    "class TokenClassificationHead(BaseHead):\n",
    "    def __init__(self, task, hidden_size, hidden_dropout_prob, recurrent_layer=None,**kwargs):\n",
    "        \"\"\"From RobertaForTokenClassification\n",
    "        \n",
    "        adapted to add a recurrent layer on the tokens outputs\n",
    "        beware that \"hidden_size\" input is actually transformer output size \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_labels = len(task.LABELS)\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        if recurrent_layer:\n",
    "            # kwargs should have at least its own hidden_size\n",
    "            #     \n",
    "            self.rnn = recurrent_modules[recurrent_layer](input_size=hidden_size,**kwargs[\"rnn_config\"])\n",
    "            output_size = **kwargs[\"rnn_config\"][\"hidden_size\"]\n",
    "            self.projection = nn.Linear(output_size, self.num_labels)\n",
    "            self.classif_type = \"recurrent_layer\"\n",
    "        else:\n",
    "            self.classif_type = \"simple\"\n",
    "            self.classifier = nn.Linear(hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, unpooled):\n",
    "        unpooled = self.dropout(unpooled)\n",
    "        if self.classif_type ==\"simple\":\n",
    "            logits = self.classifier(unpooled)\n",
    "        else:# rnn\n",
    "            outputs, hn_cn = self.rnn(unpooled)\n",
    "            logits = self.classifier(outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en fait la taskhead reçoit la task d'origine dont tout paramètre défini dans task peut servir à définir \n",
    "le forward et la head. \n",
    "il suffit de réécrire la task head avec ce qu'on suppose etre la config de la task: \n",
    "ici est un model simple ou avec rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "def test(a=1,b=2):\n",
    "    return a,b\n",
    "\n",
    "def init(x,**kwargs):\n",
    "    print(test(**kwargs[\"t\"]))\n",
    "\n",
    "init(1,t={\"a\":3,\"b\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
